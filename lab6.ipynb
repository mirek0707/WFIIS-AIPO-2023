{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sDC-myjQ-Gd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Proszę wczytać przykładowy krótki film przedstawiający obraz z kamery samochodu poruszającego się po drodze i zrealizować na nim metodę wykrywania linii poprzez transformację Hough. Wynik należy zwizualizować na sekwencji wideo."
      ],
      "metadata": {
        "id": "p2mG5yltnw_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cam  = cv2.VideoCapture('/content/drive/MyDrive/AiPO/vid1.mov')\n",
        "# pobranie informacji o rozmiarze klatki i ilości klatek na sekundę\n",
        "width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cam.get(cv2.CAP_PROP_FPS))"
      ],
      "metadata": {
        "id": "P8aZA06tSL7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ustawienie parametrów wynikowego wideo\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "wyjscie = cv2.VideoWriter('/content/drive/MyDrive/AiPO/plik.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "while(cam.isOpened()):\n",
        "    # wczytanie kolejnej klatki\n",
        "    ret, frame = cam.read()\n",
        "    #przerwanie pętli w przypadku zakończenia filmu\n",
        "    if not ret:\n",
        "      cam.release()\n",
        "      break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # wykrycie krawędzi w klatce\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
        "\n",
        "    # rysowanie wykrytych linii na klatce\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            rho, theta = line[0]\n",
        "            a = np.cos(theta)\n",
        "            b = np.sin(theta)\n",
        "            x0 = a * rho\n",
        "            y0 = b * rho\n",
        "            x1 = int(x0 + 1000*(-b))\n",
        "            y1 = int(y0 + 1000*(a))\n",
        "            x2 = int(x0 - 1000*(-b))\n",
        "            y2 = int(y0 - 1000*(a))\n",
        "            cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "    #Zapis klatki do pliku wyjściowego\n",
        "    wyjscie.write(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()\n",
        "wyjscie.release()"
      ],
      "metadata": {
        "id": "xz3REkgvSL94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wczytać drugi film, przedstawiający nagranie samochodów na autostradzie. Przenieść do odcieni szarości. Stworzyć sekwencję różnic pomiędzy kolejnymi klatkami. Utworzone różnice wykorzystać jako maski na oryginalnych klatkach."
      ],
      "metadata": {
        "id": "ZdzO1QgFn37w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap  = cv2.VideoCapture('/content/drive/MyDrive/AiPO/vid2.mov')\n",
        "# pobranie informacji o rozmiarze klatki i ilości klatek na sekundę\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))"
      ],
      "metadata": {
        "id": "py9HZyEPSMAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "frame_size = (width, height)\n",
        "\n",
        "out = cv2.VideoWriter('/content/drive/MyDrive/AiPO/plik2.avi', fourcc, fps, frame_size)\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    # wczytanie kolejnej klatki\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    #przerwanie pętli w przypadku zakończenia filmu\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    gray = cv2.resize(gray, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # wygenerowanie maski na podstawie różnicy między kolejnymi klatkami\n",
        "    if 'prev_frame' in locals():\n",
        "        diff = cv2.absdiff(gray, prev_frame)\n",
        "        _, mask = cv2.threshold(diff, 100, 255, cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
        "        mask = cv2.dilate(mask, None, iterations=2)\n",
        "        mask = cv2.resize(mask, frame_size[::-1])\n",
        "    else:\n",
        "        mask = np.zeros_like(gray)\n",
        "\n",
        "    #nałożenie maski na oryginalną klatkę\n",
        "    masked_frame = cv2.bitwise_and(frame, frame, mask=cv2.resize(mask, (frame.shape[1], frame.shape[0])))\n",
        "\n",
        "    out.write(masked_frame)\n",
        "\n",
        "    # aktualizacja poprzedniej klatki\n",
        "    prev_frame = gray\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "F5dJHV34SMDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}